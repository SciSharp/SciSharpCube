{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Tensorflow;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using static Tensorflow.Binding;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using PlotNET;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using NumSharp;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int training_epochs = 1000;\n",
    "\n",
    "// Parameters\n",
    "float learning_rate = 0.01f;\n",
    "int display_step = 50;\n",
    "\n",
    "NumPyRandom rng = np.random;\n",
    "NDArray train_X, train_Y;\n",
    "int n_samples;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.array(3.3f, 4.4f, 5.5f, 6.71f, 6.93f, 4.168f, 9.779f, 6.182f, 7.59f, 2.167f,\n",
    "             7.042f, 10.791f, 5.313f, 7.997f, 5.654f, 9.27f, 3.1f);\n",
    "train_Y = np.array(1.7f, 2.76f, 2.09f, 3.19f, 1.694f, 1.573f, 3.366f, 2.596f, 2.53f, 1.221f,\n",
    "             2.827f, 3.465f, 1.65f, 2.904f, 2.42f, 2.94f, 1.3f);\n",
    "n_samples = train_X.shape[0];\n",
    "\n",
    "// tf Graph Input\n",
    "var X = tf.placeholder(tf.float32);\n",
    "var Y = tf.placeholder(tf.float32);\n",
    "\n",
    "// Set model weights \n",
    "// We can set a fixed init value in order to debug\n",
    "// var rnd1 = rng.randn<float>();\n",
    "// var rnd2 = rng.randn<float>();\n",
    "var W = tf.Variable(-0.06f, name: \"weight\");\n",
    "var b = tf.Variable(-0.73f, name: \"bias\");\n",
    "\n",
    "// Construct a linear model\n",
    "var pred = tf.add(tf.multiply(X, W), b);\n",
    "\n",
    "// Mean squared error\n",
    "var cost = tf.reduce_sum(tf.pow(pred - Y, 2.0f)) / (2.0f * n_samples);\n",
    "\n",
    "// Gradient descent\n",
    "// Note, minimize() knows to modify W and b because Variable objects are trainable=True by default\n",
    "var optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost);\n",
    "\n",
    "// Initialize the variables (i.e. assign their default value)\n",
    "var init = tf.global_variables_initializer();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "// Start training\n",
    "using (var sess = tf.Session())\n",
    "{\n",
    "    // Run the initializer\n",
    "    sess.run(init);\n",
    "\n",
    "    // Fit all training data\n",
    "    for (int epoch = 0; epoch < training_epochs; epoch++)\n",
    "    {\n",
    "        foreach (var (x, y) in zip<float>(train_X, train_Y))\n",
    "        {\n",
    "            sess.run(optimizer, \n",
    "                new FeedItem(X, x),\n",
    "                new FeedItem(Y, y));\n",
    "        }\n",
    "\n",
    "        // Display logs per epoch step\n",
    "        if ((epoch + 1) % display_step == 0)\n",
    "        {\n",
    "            var c = sess.run(cost, \n",
    "                new FeedItem(X, train_X),\n",
    "                new FeedItem(Y, train_Y));\n",
    "            Console.WriteLine($\"Epoch: {epoch + 1} cost={c} \" + $\"W={sess.run(W)} b={sess.run(b)}\");\n",
    "        }\n",
    "    }\n",
    "\n",
    "    Console.WriteLine(\"Optimization Finished!\");\n",
    "    \n",
    "    var training_cost = sess.run(cost,\n",
    "        new FeedItem(X, train_X),\n",
    "        new FeedItem(Y, train_Y));\n",
    "        \n",
    "    var plotter = new Plotter();\n",
    "    \n",
    "    plotter.Plot(\n",
    "        train_X,\n",
    "        train_Y,\n",
    "        \"Original data\", ChartType.Scatter,\"markers\");\n",
    "    plotter.Plot(\n",
    "        train_X,\n",
    "        sess.run(W) * train_X + sess.run(b),\n",
    "        \"Fitted line\", ChartType.Scatter, \"Fitted line\");\n",
    "        \n",
    "    plotter.Show();\n",
    "    \n",
    "    // Testing example\n",
    "    var test_X = np.array(6.83f, 4.668f, 8.9f, 7.91f, 5.7f, 8.7f, 3.1f, 2.1f);\n",
    "    var test_Y = np.array(1.84f, 2.273f, 3.2f, 2.831f, 2.92f, 3.24f, 1.35f, 1.03f);\n",
    "    \n",
    "    Console.WriteLine(\"Testing... (Mean square loss Comparison)\");\n",
    "    \n",
    "    var testing_cost = sess.run(tf.reduce_sum(tf.pow(pred - Y, 2.0f)) / (2.0f * test_X.shape[0]),\n",
    "        new FeedItem(X, test_X), \n",
    "        new FeedItem(Y, test_Y));\n",
    "        \n",
    "    Console.WriteLine($\"Testing cost={testing_cost}\");\n",
    "    \n",
    "    var diff = Math.Abs((float)training_cost - (float)testing_cost);\n",
    "    Console.WriteLine($\"Absolute mean square loss difference: {diff}\");\n",
    "    \n",
    "    plotter.Plot(\n",
    "        test_X,\n",
    "        test_Y,\n",
    "        \"Testing data\", ChartType.Scatter, \"markers\");\n",
    "    plotter.Plot(\n",
    "        train_X,\n",
    "        sess.run(W) * train_X + sess.run(b),\n",
    "        \"Fitted line\", ChartType.Scatter);\n",
    "        \n",
    "    plotter.Show();\n",
    "    \n",
    "    return diff < 0.01;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SciSharp Cube",
   "language": "csharp",
   "name": "csharpcore"
  },
  "language_info": {
   "file_extension": ".cs",
   "mimetype": "text/x-csharp",
   "name": ".netstandard",
   "pygments_lexer": "CSharp",
   "version": "4.0.30319"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}