{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#r \"nuget: SciSharp.TensorFlowHub, 0.0.3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Tensorflow;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using static Tensorflow.Binding;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Tensorflow.Hub;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const int img_h = 28;\n",
    "const int img_w = 28;\n",
    "int img_size_flat = img_h * img_w; // 784, the total number of pixels\n",
    "int n_classes = 10; // Number of classes, one class per digit\n",
    "// Hyper-parameters\n",
    "int epochs = 10;\n",
    "int batch_size = 100;\n",
    "float learning_rate = 0.001f;\n",
    "int h1 = 200; // number of nodes in the 1st hidden layer\n",
    "int display_freq = 100;\n",
    "float accuracy_test = 0f;\n",
    "float loss_test = 1f;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "private Tensor fc_layer(Tensor x, int num_units, string name, bool use_relu = true)\n",
    "{\n",
    "    var in_dim = x.shape[1];\n",
    "\n",
    "    var initer = tf.truncated_normal_initializer(stddev: 0.01f);\n",
    "    var W = tf.get_variable(\"W_\" + name,\n",
    "                dtype: tf.float32,\n",
    "                shape: (in_dim, num_units),\n",
    "                initializer: initer);\n",
    "\n",
    "    var initial = tf.constant(0f, num_units);\n",
    "    var b = tf.get_variable(\"b_\" + name,\n",
    "                dtype: tf.float32,\n",
    "                initializer: initial);\n",
    "\n",
    "    var layer = tf.matmul(x, W) + b;\n",
    "    if (use_relu)\n",
    "        layer = tf.nn.relu(layer);\n",
    "\n",
    "    return layer;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var graph = new Graph().as_default();\n",
    "\n",
    "// Placeholders for inputs (x) and outputs(y)\n",
    "var x = tf.placeholder(tf.float32, shape: (-1, img_size_flat), name: \"X\");\n",
    "var y = tf.placeholder(tf.float32, shape: (-1, n_classes), name: \"Y\");\n",
    "\n",
    "// Create a fully-connected layer with h1 nodes as hidden layer\n",
    "var fc1 = fc_layer(x, h1, \"FC1\", use_relu: true);\n",
    "// Create a fully-connected layer with n_classes nodes as output layer\n",
    "var output_logits = fc_layer(fc1, n_classes, \"OUT\", use_relu: false);\n",
    "// Define the loss function, optimizer, and accuracy\n",
    "var logits = tf.nn.softmax_cross_entropy_with_logits(labels: y, logits: output_logits);\n",
    "var loss = tf.reduce_mean(logits, name: \"loss\");\n",
    "var optimizer = tf.train.AdamOptimizer(learning_rate: learning_rate, name: \"Adam-op\").minimize(loss);\n",
    "var correct_prediction = tf.equal(tf.argmax(output_logits, 1), tf.argmax(y, 1), name: \"correct_pred\");\n",
    "var accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name: \"accuracy\");\n",
    "\n",
    "// Network predictions\n",
    "var cls_prediction = tf.argmax(output_logits, axis: 1, name: \"predictions\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "void Train(Session sess, Datasets<MnistDataSet> mnist)\n",
    "{\n",
    "    // Number of training iterations in each epoch\n",
    "    var num_tr_iter = mnist.Train.Labels.len / batch_size;\n",
    "\n",
    "    var init = tf.global_variables_initializer();\n",
    "    sess.run(init);\n",
    "\n",
    "    float loss_val = 100.0f;\n",
    "    float accuracy_val = 0f;\n",
    "\n",
    "    foreach (var epoch in range(epochs))\n",
    "    {\n",
    "        Console.WriteLine($\"Training epoch: {epoch + 1}\");\n",
    "        // Randomly shuffle the training data at the beginning of each epoch \n",
    "        var (x_train, y_train) = mnist.Randomize(mnist.Train.Data, mnist.Train.Labels);\n",
    "\n",
    "        foreach (var iteration in range(num_tr_iter))\n",
    "        {\n",
    "            var start = iteration * batch_size;\n",
    "            var end = (iteration + 1) * batch_size;\n",
    "            var (x_batch, y_batch) = mnist.GetNextBatch(x_train, y_train, start, end);\n",
    "\n",
    "            // Run optimization op (backprop)\n",
    "            sess.run(optimizer, new FeedItem(x, x_batch), new FeedItem(y, y_batch));\n",
    "\n",
    "            if (iteration % display_freq == 0)\n",
    "            {\n",
    "                // Calculate and display the batch loss and accuracy\n",
    "                var result = sess.run(\n",
    "                    new[] { loss, accuracy },\n",
    "                    new FeedItem(x, x_batch),\n",
    "                    new FeedItem(y, y_batch));\n",
    "                loss_val = result[0];\n",
    "                accuracy_val = result[1];\n",
    "                Console.WriteLine($\"iter {iteration.ToString(\"000\")}: Loss={loss_val.ToString(\"0.0000\")}, Training Accuracy={accuracy_val.ToString(\"P\")}\");\n",
    "            }\n",
    "        }\n",
    "\n",
    "        // Run validation after every epoch\n",
    "        var results1 = sess.run(\n",
    "            new[] { loss, accuracy },\n",
    "            new FeedItem(x, mnist.Validation.Data),\n",
    "            new FeedItem(y, mnist.Validation.Labels)\n",
    "            );\n",
    "            \n",
    "        loss_val = results1[0];\n",
    "        accuracy_val = results1[1];\n",
    "        Console.WriteLine(\"---------------------------------------------------------\");\n",
    "        Console.WriteLine($\"Epoch: {epoch + 1}, validation loss: {loss_val.ToString(\"0.0000\")}, validation accuracy: {accuracy_val.ToString(\"P\")}\");\n",
    "        Console.WriteLine(\"---------------------------------------------------------\");\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "void Test(Session sess, Datasets<MnistDataSet> mnist)\n",
    "{\n",
    "    var result = sess.run(\n",
    "        new[] { loss, accuracy },\n",
    "        new FeedItem(x, mnist.Test.Data),\n",
    "        new FeedItem(y, mnist.Test.Labels)\n",
    "    );\n",
    "    \n",
    "    loss_test = result[0];\n",
    "    accuracy_test = result[1];\n",
    "    Console.WriteLine(\"---------------------------------------------------------\");\n",
    "    Console.WriteLine($\"Test loss: {loss_test.ToString(\"0.0000\")}, test accuracy: {accuracy_test.ToString(\"P\")}\");\n",
    "    Console.WriteLine(\"---------------------------------------------------------\");\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var mnist = await MnistModelLoader.LoadAsync(\"mnist\", true);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using(var sess = tf.Session())\n",
    "{\n",
    "    Train(sess, mnist);\n",
    "    Test(sess, mnist);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_test < 0.09 && accuracy_test > 0.95"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SciSharp Cube",
   "language": "csharp",
   "name": "csharpcore"
  },
  "language_info": {
   "file_extension": ".cs",
   "mimetype": "text/x-csharp",
   "name": ".netstandard",
   "pygments_lexer": "CSharp",
   "version": "4.0.30319"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
